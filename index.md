## The Need for Speed

Honestly, no one likes a slow-loading website. But initially, it seems webmasters didn't care too much about speed. I mean they cared but not so much! After some research shows that for every second slower a website is, it is losing money. Then boom, everyone started hustling for speed.

I feel that most people hustling for speed are doing it so that their website doesn't lose money or so they don't lose their ranking in Google. While this may not necessarily be a bad thing, the problem here is the intent, so if you were not losing money or there was no possibility of losing your Google ranking, speed would not be of concern?

I feel that things like optimizing for speed should be done just for user experience. That is where it should start and stop. 

The need for speed should arise if you are certain that the user experience is bad as regards the speed of your site.


## Pressure from the big guys

In life, you face peer pressure, but if you are a Webmaster you face search engine pressure. They are never satisfied.

The big guys like Google and Bing can make your life a living hell as a webmaster. They never stop demanding standards that even their products cannot meet.

The most recent is core web vitals. With some metrics that are hard to get for some niches. You have to sacrifice a lot to get these metrics right. The issue is that some of the things you sacrifice can end up hurting the user experience that these metrics are 'supposed' to help with.

In some cases, to satisfy the big guys, just make your website look exactly like the [fastest website in the world](https://fastestwebsite.net/).  

It can be a good thing if giants like Google and Bing actually have a real-world user group of different demographics, where they seek their seek their opinion.


## Don't optimize for bots

Take this advice from me, no matter the pressure, do not optimize for bots. Unfortunately, most people in the web development and optimization industry optimize their websites for bots not humans. Some plugin makers even develop plugins that are meant to fool bots. They will delay the loading of assets when a bot from a testing tool visit to give high scores. 

Main, people actually take those green scores and 100/100 scores seriously. I don't want to laugh. I have been in some Facebook groups where people show off their scores as if it is a ticket to Heaven.

But the problem is, if you actually run their website through PageSpeed Insight, you will notice that while the lab data is all green and 100/100. The field data and origin summary is all red and failed.

So in summary, they ended up optimizing for bots, not humans. What a way to actually fool yourself.


## Do your best for User Experience and leave the rest
 
The best approach is to think of what is best for your user experience and then leave the rest.

And please, I beg you, if you have auto-play video or music on your website, stop it. Never have I heard a user say they like auto-play but yet, many websites use these shady tactics just to boost revenue. You end up forcing users to either quit your site or use some browser extension to block it.

Stop placing too many ads. Don't get greedy. When you have too many ads, the User Experience is terrible. And some users will be forced to use adblockers.

[Remove unused CSS](https://targettrend.com/remove-unused-css/). It is called Unused CSS for a reason.

Minify your JS, CSS, and HTML.

Get a fast web host and deploy a CDN to help, especially if you have many users around the world.



